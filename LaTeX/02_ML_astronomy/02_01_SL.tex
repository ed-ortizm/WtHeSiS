\subsection{Supervised learning (SL)}

With the advent of computers and the digitalization of data, even the model-fitting paradigm can be done really quickly by programming a computer. The problem with this approach is that in it, a set of rules has to be programmed, according to the model considered in order to accomplish the task. Nonetheless, if the complexity of the correlation among the features of the data increases, as is the case with the advent of Big-Data in astronomy, the set of rules will be obsolete and a new set of rules will have to be written, however, and as mentioned in the introduction of this section, this requires a model which is pretty impossible to came up with if the complexity of the problem is huge. In order to avoid that, we have to program and train a ML algorithm. In a broad sense and citing Arthur Samuel (1959) \cite{Geron2017}, Machine Learning can be defined as ``the field of study that gives computers the ability to learn without being explicitly programmed". SL is the case when the machine learns using domain knowledge from a human expert.\\

Regarding astronomy, we can picture the case where we have spectra from millions of galaxies and where our goal is to obtain, let's say: their star formation rates \cite{DelliVeneri2019}, their metallicity \cite{Acquaviva2016} \cite{Ucci2017}, density, column density, and ionization parameter \cite{Ucci2017} using SL. In plain English, to make the machine learn the relation among the spectra and the quantities of interest, a data set with those relations (already computed by a human expert), is compulsory (that's the supervision). That knowledge is then fed to the algorithm so it learns the relations (in a black-box approach), tweaking some parameters according to the type of ML model used (hyper-parameters) and the nature of the studied data (model parameters) \cite{Baron2019}. After the relations are learned, we use the ML as a tool to make predictions of the target variables on new galaxies.\\

In the language of statistics, we can define the task of supervised ML with the following ingredients \cite{Hastie2003}:
 \begin{enumerate}
     \item $\vec{X}$: a real-valued random input vector.
     \item $\vec{Y}$: a real-valued random output vector.
     \item $Pr(\vec{X},\vec{Y})$: the joint distribution between $\vec{X}$ and $\vec{Y}$.
     \item $\mathcal{L}(Y,f(\vec{X})$: the loss function for penalizing errors in the predictions made by the machine
 \end{enumerate}

The ultimate goal is to find the optimal solution for $Y = f(X)$ such that our loss function is minimized. That's the mathematical formulation of the problem, but since reality is trickier, what one truly does is to attempt to achieve this, but as an approximation with the available data.\\

The loss function $\mathcal{L}(Y,f(X))$ is metric a that measures how much the prediction $f(\vec{X})$ deviates from the target variables $\vec{Y}$. Several metrics can be chosen, like the Mean Square Error (MSE) or the Mean Absolute Error (MAE), just to mention a couple of them:
\begin{eqnarray*}
MSE &=& \frac{1}{N} \sum_{i=1}^{N}\left( \vec{Y} - f(\vec{X})\right)^2\\
MAE &=& \frac{1}{N} \sum_{i=1}^{N}\left| \vec{Y} - f(\vec{X})\right|
\end{eqnarray*}

Depending on the error metric chosen, we will get a solution to our optimization problem \cite{Hastie2003}. The error metric has to be chosen according to the needs of our science case, for example, the MSE metric is better suited to consider the information contained in outliers, while the MAE is not. The loss function is optimized according to the hyper-parameters of the ML model so we obtain the better performing ML model \cite{Baron2019}
